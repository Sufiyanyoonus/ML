{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VX_sI_nVMjBlHD4siUGW0x4dfjiUZlVv",
      "authorship_tag": "ABX9TyOO0aYPTYky3wAoWLsXRqzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sufiyanyoonus/ML/blob/main/Formative_Assessment_NLP_Emotion_Classification_in_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkCBDdELlj_7",
        "outputId": "69f85fe4-5b43-4d7d-aa3e-1c6930939ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Comment Emotion\n",
            "0     i seriously hate one subject to death but now ...    fear\n",
            "1                    im so full of life i feel appalled   anger\n",
            "2     i sit here to write i start to dig out my feel...    fear\n",
            "3     ive been really angry with r and i feel like a...     joy\n",
            "4     i feel suspicious if there is no one outside l...    fear\n",
            "...                                                 ...     ...\n",
            "5932                 i begun to feel distressed for you    fear\n",
            "5933  i left feeling annoyed and angry thinking that...   anger\n",
            "5934  i were to ever get married i d have everything...     joy\n",
            "5935  i feel reluctant in applying there because i w...    fear\n",
            "5936  i just wanted to apologize to you because i fe...   anger\n",
            "\n",
            "[5937 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the data file from Drive\n",
        "file_path = '/content/drive/MyDrive/nlp_dataset.csv'\n",
        "import pandas as pd\n",
        "df = pd.read_csv(file_path)\n",
        "print (df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOfWOPURmzJN",
        "outputId": "37c8bbd7-252c-4c64-fd86-1a61abf959e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "KeZlz0S-om5s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Cleaning: Removing unnecessary characters like punctuation, numbers, or special symbols."
      ],
      "metadata": {
        "id": "XljwG_AitGoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data for lemmatization and stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJm5rjdFrkHi",
        "outputId": "e76bec32-d8a8-4305-f3e0-5774f977b912"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make the object for stop words and lemmetixzer\n",
        "# stop words are the common words that used in every sentence due to that it is unnecessary for nltk\n",
        "stop_words=set(stopwords.words('english'))\n",
        "\n",
        "# lemmatizer is used for making the word to dict root word for better raedeabily\n",
        "lemmatizer=WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "sKQ0KNkOrqOM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing (text):\n",
        "  # Converting all the letters onto lowercase for uniformity for all words\n",
        "  text=text.lower()\n",
        "\n",
        "   # Remove all characters that are not alphabets\n",
        "  text=re.sub(r'[^a-z\\s]','',text)\n",
        "\n",
        "  # converting the senetence into words for machine readenility and for further steps\n",
        "  words=word_tokenize(text)\n",
        "\n",
        "  # lemmatizing (changing the word into dict root word) the word if the word is not in the stop words (words which are commonly used)\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "\n",
        "\n",
        "  # join the remaining words\n",
        "  return ' '.join(words)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "tWsowDe-tBHa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_text']=df['Comment'].apply(preprocessing) # apllything the preprocessing ti ccolumn\n",
        "\n",
        "print(df[['Comment','cleaned_text']].head(10)) # print the preprossed and not  preprossesed column\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0I5a5EAwdnB",
        "outputId": "e7fe56e7-07f1-429b-eea5-e61f4b13233e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Comment  \\\n",
            "0  i seriously hate one subject to death but now ...   \n",
            "1                 im so full of life i feel appalled   \n",
            "2  i sit here to write i start to dig out my feel...   \n",
            "3  ive been really angry with r and i feel like a...   \n",
            "4  i feel suspicious if there is no one outside l...   \n",
            "5  i feel jealous becasue i wanted that kind of l...   \n",
            "6  when a friend of mine keeps telling me morbid ...   \n",
            "7  i finally fell asleep feeling angry useless an...   \n",
            "8       i feel a bit annoyed and antsy in a good way   \n",
            "9  i feel like i ve regained another vital part o...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  seriously hate one subject death feel reluctan...  \n",
            "1                         im full life feel appalled  \n",
            "2  sit write start dig feeling think afraid accep...  \n",
            "3  ive really angry r feel like idiot trusting fi...  \n",
            "4  feel suspicious one outside like rapture happe...  \n",
            "5  feel jealous becasue wanted kind love true con...  \n",
            "6  friend mine keep telling morbid thing happened...  \n",
            "7  finally fell asleep feeling angry useless stil...  \n",
            "8                    feel bit annoyed antsy good way  \n",
            "9  feel like regained another vital part life living  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "Dy7C0O162Gg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# create the object\n",
        "vectorizer= TfidfVectorizer()\n",
        "\n",
        "# transform\n",
        "tfdif_matrix=vectorizer.fit_transform(df['cleaned_text'])\n",
        "\n",
        "# converting to data frame better visualiztaion\n",
        "tfdif_df=pd.DataFrame(tfdif_matrix.toarray(),columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# print the converetd data frame\n",
        "print(tfdif_df.head(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL2IocXO1f7h",
        "outputId": "a4964a24-5e9a-415f-a068-6498512d1fbf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    aa  aac  aaron   ab  abandon  abandoned  abandonment  abbigail  abc  \\\n",
            "0  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "1  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "2  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "3  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "4  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "5  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "6  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "7  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "8  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "9  0.0  0.0    0.0  0.0      0.0        0.0          0.0       0.0  0.0   \n",
            "\n",
            "   abdomen  ...  zendikar  zero  zest  zhu  zipline  zombie  zone  zonisamide  \\\n",
            "0      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "1      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "2      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "3      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "4      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "5      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "6      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "7      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "8      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "9      0.0  ...       0.0   0.0   0.0  0.0      0.0     0.0   0.0         0.0   \n",
            "\n",
            "    zq  zumba  \n",
            "0  0.0    0.0  \n",
            "1  0.0    0.0  \n",
            "2  0.0    0.0  \n",
            "3  0.0    0.0  \n",
            "4  0.0    0.0  \n",
            "5  0.0    0.0  \n",
            "6  0.0    0.0  \n",
            "7  0.0    0.0  \n",
            "8  0.0    0.0  \n",
            "9  0.0    0.0  \n",
            "\n",
            "[10 rows x 7970 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Cnp5qB6fR-",
        "outputId": "6d046d9c-de77-490f-fd35-369daf2faf05"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['aa', 'aac', 'aaron', 'ab', 'abandon', 'abandoned', 'abandonment',\n",
            "       'abbigail', 'abc', 'abdomen',\n",
            "       ...\n",
            "       'zendikar', 'zero', 'zest', 'zhu', 'zipline', 'zombie', 'zone',\n",
            "       'zonisamide', 'zq', 'zumba'],\n",
            "      dtype='object', length=7970)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the data"
      ],
      "metadata": {
        "id": "0HQTeuTo7utR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(tfdif_matrix,df['Emotion'],test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zcRNi82V7GBf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "## Naive bayes\n",
        "###1. Naive Bayes Classifier\n",
        "###What It Is:\n",
        "###Naive Bayes is a simple and fast algorithm that uses probabilities to ###classify data. It assumes that each word in a text is independent of the others.\n",
        "\n",
        "###Why It’s Good for Emotion Classification:\n",
        "\n",
        "###Easy to Use: Quick to train and run, making it great for large datasets.\n",
        "Good for Text: Works well with text data, like identifying emotions from words.\n",
        "Fast Predictions: Can quickly predict emotions based on word frequencies"
      ],
      "metadata": {
        "id": "s0S7AVID862M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import  MultinomialNB\n",
        "\n",
        "naive= MultinomialNB()\n",
        "naive.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "y_pred_nb=naive.predict(x_test)\n",
        "\n",
        "print(\"Accuracy\",accuracy_score(y_test,y_pred_nb))\n",
        "print(\"\\nClassification report of the naive bayes\\n\",classification_report(y_test,y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRDrS0PF88Rm",
        "outputId": "9d8a90cb-3302-4673-eed7-6723ba44da5e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9082491582491582\n",
            "\n",
            "Classification report of the naive bayes\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.93      0.91       392\n",
            "        fear       0.92      0.92      0.92       416\n",
            "         joy       0.93      0.88      0.90       380\n",
            "\n",
            "    accuracy                           0.91      1188\n",
            "   macro avg       0.91      0.91      0.91      1188\n",
            "weighted avg       0.91      0.91      0.91      1188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Support Vector Machine (SVM)\n",
        "###What It Is:\n",
        "###SVM is an algorithm that finds the best line (or hyperplane) to separate different categories (like different emotions) in data.\n",
        "\n",
        "###Why It’s Good for Emotion Classification:\n",
        "\n",
        "###Handles Lots of Features: Works well even when there are many words (features) compared to the number of examples (texts).\n",
        "###Robust: Can avoid overfitting, which helps it perform well on new data.\n",
        "###Clear Decision Boundaries: Focuses on creating clear separations between different emotions."
      ],
      "metadata": {
        "id": "rZhiDFJNBC0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "vector=SVC()\n",
        "vector.fit(x_train,y_train)\n",
        "\n",
        "y_pred_vector=vector.predict(x_test)\n",
        "# Evaluate the SVM model\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_vector))\n",
        "print(\"Classification Report for SVM:\\n\", classification_report(y_test, y_pred_vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoaB9k45_ok_",
        "outputId": "4437d2b4-a588-4cca-c4a3-81ae1414f592"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9318181818181818\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.93      0.93      0.93       392\n",
            "        fear       0.97      0.90      0.93       416\n",
            "         joy       0.90      0.97      0.93       380\n",
            "\n",
            "    accuracy                           0.93      1188\n",
            "   macro avg       0.93      0.93      0.93      1188\n",
            "weighted avg       0.93      0.93      0.93      1188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# from the evaluvation conducted we can see that the accuracy and fi score is better in SVB than NIave bias  "
      ],
      "metadata": {
        "id": "f18A8tzfBNm8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkrsyGYqDzJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}